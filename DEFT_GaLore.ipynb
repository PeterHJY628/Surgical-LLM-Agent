{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ef9abd52448493bb4811ccec57b1b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_930648df8b9746c981e55ef68a91d6d6",
              "IPY_MODEL_63f23f243cbb469b85450316e82f94c6",
              "IPY_MODEL_25d7e8c0742c43e0a6bdd1daa91eca32"
            ],
            "layout": "IPY_MODEL_aba72f21d4364b8389a2e208970941bf"
          }
        },
        "930648df8b9746c981e55ef68a91d6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37e506fcfb134dedb7e1306fe7cd5b57",
            "placeholder": "​",
            "style": "IPY_MODEL_93f16c29f1d54b2a9613ea17a0511f44",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "63f23f243cbb469b85450316e82f94c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4b192b42e43448a8a4600e06cc966e8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba3ac757b5204eefaf81b0b528269284",
            "value": 3
          }
        },
        "25d7e8c0742c43e0a6bdd1daa91eca32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a05290dee3c42168abec10bd815fbec",
            "placeholder": "​",
            "style": "IPY_MODEL_403814e289eb47619a1e4f645390ea3d",
            "value": " 3/3 [04:03&lt;00:00, 72.22s/it]"
          }
        },
        "aba72f21d4364b8389a2e208970941bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e506fcfb134dedb7e1306fe7cd5b57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f16c29f1d54b2a9613ea17a0511f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4b192b42e43448a8a4600e06cc966e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba3ac757b5204eefaf81b0b528269284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a05290dee3c42168abec10bd815fbec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "403814e289eb47619a1e4f645390ea3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterHJY628/Surgical-LLM-Agent/blob/main/DEFT_GaLore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md_Fo8mzN-so",
        "outputId": "b248373d-b055-4d7b-bd43-70a1a6120f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Created output directories in Google Drive at: /content/drive/MyDrive/surgical_llm_demo\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Downloading model weights...\n",
            "Model weights already exist at /content/drive/MyDrive/surgical_llm_demo/models/DEFT-GaLore_weight\n",
            "Downloading datasets...\n",
            "Surgical-VQA_V.csv already exists\n",
            "Overlaying_V.csv already exists\n",
            "Segment-MRI_V.csv already exists\n",
            "Segment-Video_V.csv already exists\n",
            "Detect-Instrument_V.csv already exists\n",
            "2model_V.csv already exists\n",
            "3model_V.csv already exists\n"
          ]
        }
      ],
      "source": [
        "# Surgical LLM Agent Demo\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create output directories in Google Drive\n",
        "import os\n",
        "output_base_dir = '/content/drive/MyDrive/surgical_llm_demo'\n",
        "model_dir = f'{output_base_dir}/models/DEFT-GaLore_weight'\n",
        "data_dir = f'{output_base_dir}/datasets'\n",
        "results_dir = f'{output_base_dir}/results'\n",
        "metrics_dir = f'{output_base_dir}/metrics'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "for directory in [output_base_dir, model_dir, data_dir, results_dir, metrics_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(f\"Created output directories in Google Drive at: {output_base_dir}\")\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q transformers==4.45.1 datasets==3.0.1 evaluate==0.4.3 gdown nltk torch==2.4.0 torchvision==0.19.0\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q bitsandbytes>=0.43.2\n",
        "!pip install -q accelerate\n",
        "!pip install rouge_score\n",
        "\n",
        "# Download necessary NLTK data\n",
        "import nltk\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Download model weights using gdown (NOTE: Replace with your actual file ID)\n",
        "print(\"Downloading model weights...\")\n",
        "MODEL_FILE_ID = \"1l5tJ41cQa0M8z0UF8Az96DX1sZMAV0Yt\"  # Replace with the actual file ID from Google Drive\n",
        "#https://drive.google.com/drive/folders/1c6dLqsDnivVClRBdzfeZbd4HvLkIEfah?usp=drive_link\n",
        "#https://drive.google.com/drive/folders/1l5tJ41cQa0M8z0UF8Az96DX1sZMAV0Yt?usp=sharing\n",
        "\n",
        "# Check if model is already downloaded\n",
        "if not os.path.exists(f\"{model_dir}/config.json\"):\n",
        "    !gdown --folder {MODEL_FILE_ID} -O {model_dir}\n",
        "    print(f\"Model weights downloaded to {model_dir}\")\n",
        "else:\n",
        "    print(f\"Model weights already exist at {model_dir}\")\n",
        "\n",
        "# Download datasets\n",
        "print(\"Downloading datasets...\")\n",
        "DATASET_FILE_IDS = {\n",
        "    \"Surgical-VQA_V.csv\": \"1rjv3PzKHqz5BjJn8anR2jSwNTPS2k0Ak\",\n",
        "    \"Overlaying_V.csv\": \"1gFpt8kjoc0kzTBXXiRlYgwDC-HzlSGAr\",\n",
        "    \"Segment-MRI_V.csv\": \"1rSJfPEqg24fhk4MybqpRw652orLfgojc\",\n",
        "    \"Segment-Video_V.csv\": \"1lo0xEKcJgMPy0T0AXfRIjNbrSdJyrXkR\",\n",
        "    \"Detect-Instrument_V.csv\": \"1A4c5ieW6P_oqMnWRybl6NmtmTshsPX1n\",\n",
        "    \"2model_V.csv\": \"1dl_81gH1o06ZYLn1FuL8J4INxq3cLqnu\",\n",
        "    \"3model_V.csv\": \"1WwLigg0kjRHyxkOaSYc8V2M8GFK9qlc9\"\n",
        "}\n",
        "\n",
        "# https://drive.google.com/file/d/1rjv3PzKHqz5BjJn8anR2jSwNTPS2k0Ak/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1gFpt8kjoc0kzTBXXiRlYgwDC-HzlSGAr/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1rSJfPEqg24fhk4MybqpRw652orLfgojc/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1lo0xEKcJgMPy0T0AXfRIjNbrSdJyrXkR/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1A4c5ieW6P_oqMnWRybl6NmtmTshsPX1n/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1dl_81gH1o06ZYLn1FuL8J4INxq3cLqnu/view?usp=drive_link\n",
        "# https://drive.google.com/file/d/1WwLigg0kjRHyxkOaSYc8V2M8GFK9qlc9/view?usp=drive_link\n",
        "\n",
        "# Download each dataset\n",
        "for filename, file_id in DATASET_FILE_IDS.items():\n",
        "    if not os.path.exists(f\"{data_dir}/{filename}\"):\n",
        "        !gdown {file_id} -O {data_dir}/{filename}\n",
        "        print(f\"Downloaded {filename}\")\n",
        "    else:\n",
        "        print(f\"{filename} already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Fuctions"
      ],
      "metadata": {
        "id": "ii0pdy3jOJ71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "import re\n",
        "import evaluate\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# ---------------------------- Utility Function ----------------------------\n",
        "def generate_SM(que: str) -> str:\n",
        "    return (\n",
        "        \"You are a surgical AI agent assisting in pituitary surgery. Your job is to handle surgeons' queries efficiently by choosing appropriate text-promptable AI models and generating corresponding prompts.\\n\"\n",
        "        \"Available models: Segment-Video, Segment-MRI, Track-Instrument, Surgical-VQA, Overlaying.\\n\"\n",
        "        \"Question: {que}\\n\"\n",
        "        \"- Use ONE model if query focuses on a single, simple aspect:\\n\"\n",
        "        \"Example (single-model):\\n\"\n",
        "        \"Model: Segment-Video\\nPrompt: Segment the sella in the video.\\n\"\n",
        "        \"- Use MULTIPLE models if query requires several types of information:\\n\"\n",
        "        \"Example (multi-model):\\n\"\n",
        "        \"Step1:\\nModel: Segment-MRI\\nPrompt: Segment the pituitary tumor from MRI.\\n\"\n",
        "        \"Step2:\\nModel: Segment-Video\\nPrompt: Segment the sella in the video.\\n\"\n",
        "        \"Now, follow the same format to answer the provided question—no extra text, labels, or formatting.\"\n",
        "    ).format(que=que)\n",
        "\n",
        "def generate_answer(question, model, tokenizer):\n",
        "    model.eval()\n",
        "    question = generate_SM(question)\n",
        "    input_text = f\"Query:\\n{question}\\nResponse:\\n\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=200, pad_token_id=tokenizer.eos_token_id)\n",
        "    answer = tokenizer.decode(output[0], skip_special_tokens=True).split(\"Response:\\n\")[-1].strip()\n",
        "    return answer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2SiZuvOsOLxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference"
      ],
      "metadata": {
        "id": "4cpn5t7iOQHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the model using BitsAndBytes for efficient loading\n",
        "print(\"Loading model...\")\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "try:\n",
        "    # Load model and tokenizer\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_dir,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=False)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    print(\"Model loaded successfully!\")\n",
        "\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ],
      "metadata": {
        "id": "_-xgtBZPORzF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "4ef9abd52448493bb4811ccec57b1b1a",
            "930648df8b9746c981e55ef68a91d6d6",
            "63f23f243cbb469b85450316e82f94c6",
            "25d7e8c0742c43e0a6bdd1daa91eca32",
            "aba72f21d4364b8389a2e208970941bf",
            "37e506fcfb134dedb7e1306fe7cd5b57",
            "93f16c29f1d54b2a9613ea17a0511f44",
            "e4b192b42e43448a8a4600e06cc966e8",
            "ba3ac757b5204eefaf81b0b528269284",
            "8a05290dee3c42168abec10bd815fbec",
            "403814e289eb47619a1e4f645390ea3d"
          ]
        },
        "outputId": "2fdcbb5c-2639-42b0-cb11-92d12239d297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ef9abd52448493bb4811ccec57b1b1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Input question\n",
        "# Single model case:\n",
        "print(\"The question of single model case is:\\nCan you show me where to be careful and not make incisions?\\n\")\n",
        "# Define the sample query question here:\n",
        "question1 = \"Can you show me where to be careful and not make incisions?\"\n",
        "\n",
        "answer1 = generate_answer(question1, model, tokenizer)\n",
        "print(\"The answer generated by agent is:\")\n",
        "print(answer1)\n",
        "\n",
        "# Multiple model case:\n",
        "print(\"\\nThe question of multiple models case is:\\nIdentift if I'm prepared to transition to tumor excision with the pituitary rongeur?\\n\")\n",
        "question2 = \"Identift if I'm prepared to transition to tumor excision with the pituitary rongeur?\"\n",
        "\n",
        "answer2 = generate_answer(question2, model, tokenizer)\n",
        "print(\"The answer generated by agent is:\")\n",
        "print(answer2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkmjUPd2EFeY",
        "outputId": "7297b296-fc47-4494-ac98-85804a085c80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The question of single model case is:\n",
            "Can you show me where to be careful and not make incisions?\n",
            "\n",
            "The answer generated by agent is:\n",
            "Model: Segment-Video\n",
            "Prompt: Segment the internal skull structures.\n",
            "\n",
            "The question of multiple models case is:\n",
            "Identift if I'm prepared to transition to tumor excision with the pituitary rongeur?\n",
            "\n",
            "The answer generated by agent is:\n",
            "Step1:\n",
            "Model: Track-Instrument\n",
            "Prompt: Verify the presence and correct usage of the pituitary rongeur.\n",
            "Step2:\n",
            "Model: Surgical-VQA\n",
            "Prompt: Confirm readiness for the tumour excision step and provide brief recommendations.\n"
          ]
        }
      ]
    }
  ]
}